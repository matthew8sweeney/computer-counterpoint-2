{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "music testing.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "S-V2uLth2ex3",
        "K-YUVBMi3uTv",
        "Shy7EqCXziKY"
      ],
      "toc_visible": true,
      "mount_file_id": "13O1VO2vUn1Xty2N3V1IylOikgZny2_ox",
      "authorship_tag": "ABX9TyOGs8vBsdDKAxBKqqJ7Lq8Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matthew8sweeney/computer-counterpoint-2/blob/master/music_testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GK6ObTH-usJ"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5Q8218h0KAY"
      },
      "source": [
        "# for music analysis\n",
        "import music21 as m21\n",
        "\n",
        "# for fetching data from the internet\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.request import urlopen, urlretrieve\n",
        "import time\n",
        "\n",
        "# for displaying music notation\n",
        "import os\n",
        "from IPython.display import Image, Audio, clear_output\n",
        "\n",
        "# for processing data\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "# for model\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "# for training\n",
        "import matplotlib.pyplot as plt\n",
        "from copy import deepcopy"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4huw2V1t3T8"
      },
      "source": [
        "## Utility\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xm7ElydFr9Gt",
        "outputId": "e00ba32c-2ed2-4294-a226-1f71d554df6e"
      },
      "source": [
        "# Set device to point to a GPU if we have one, CPU otherwise.\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device_cpu = torch.device(\"cpu\")\n",
        "device"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-V2uLth2ex3"
      },
      "source": [
        "### Music21 `.show()` Setup\n",
        "Allows music21 methods for showing music notation to work properly in Colab environment.  \n",
        "From a [notebook](https://colab.research.google.com/gist/mscuthbert/431dee45c01598a0c11bc27823bd1c5b/music21_setup.ipynb) by Michael Cuthbert, who also created music21."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYzCo5rXxhzM",
        "outputId": "1d802fc8-c608-4142-d162-2836040c3e52"
      },
      "source": [
        "!apt-get install musescore > /dev/null\n",
        "!apt-get install xvfb > /dev/null\n",
        "!sh -e /etc/init.d/x11-common start\n",
        "os.putenv('DISPLAY', ':99.0')\n",
        "!start-stop-daemon --start --pidfile /var/run/xvfb.pid --make-pidfile --background --exec /usr/bin/Xvfb -- :99 -screen 0 1024x768x24 -ac +extension GLX +render -noreset\n",
        "\n",
        "us = m21.environment.UserSettings()\n",
        "us[\"musescoreDirectPNGPath\"] = \"/usr/bin/mscore\"\n",
        "us[\"directoryScratch\"] = \"/tmp/\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Setting up X socket directories...\n",
            "   ...done.\n",
            "/usr/bin/Xvfb already running.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-YUVBMi3uTv"
      },
      "source": [
        "### Functions for Playing Audio and Showing Notation.  \n",
        "From a [notebook](https://colab.research.google.com/drive/17Fql7pyK3xsO8KmZorvb1tBoPomidCPB) by Robby Nevels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SctZx_RP6GQv"
      },
      "source": [
        "!apt-get install lilypond > /dev/null\n",
        "!apt-get install fluidsynth > /dev/null\n",
        "!cp /usr/share/sounds/sf2/FluidR3_GM.sf2 ./font.sf2"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIcHZA4Htw2Y"
      },
      "source": [
        "def show_lily(m21_music):\n",
        "    \"\"\"Liable to break if given music containing rests\"\"\"\n",
        "    display(Image(str(m21_music.write('lily.png'))))\n",
        "\n",
        "def play(m21_music):\n",
        "    filename = m21_music.write('mid')\n",
        "    !fluidsynth -ni font.sf2 $filename -F $filename\\.wav -r 16000 > /dev/null\n",
        "    display(Audio(filename + '.wav'))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGx4LNguCPzx"
      },
      "source": [
        "# this one was by me\n",
        "def show_example(m21_music):\n",
        "    play(m21_music)\n",
        "    m21_music.show()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Shy7EqCXziKY"
      },
      "source": [
        "### Generate one-hot vectors from indices\n",
        "Found on Rishabh Agrahari's [Pytorch forum](https://discuss.pytorch.org/t/convert-int-into-one-hot-format/507/26) post."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3pnRhPH0rS1"
      },
      "source": [
        "def ixs_to_oh(labels, num_classes):\n",
        "    \"\"\"\n",
        "    Converts indices to one-hot vector form.\n",
        "\n",
        "    Args:\n",
        "        labels (LongTensor): class labels, sized [N,].\n",
        "        num_classes (int): number of classes.\n",
        "\n",
        "    Returns:\n",
        "        tensor: encoded labels, sized [N, #classes].\n",
        "    \"\"\"\n",
        "    y = torch.eye(num_classes) \n",
        "    return y[labels] "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGU2hoKaG_5P",
        "outputId": "f7738745-bb64-420d-a52c-0ec49b45157b"
      },
      "source": [
        "ixs_to_oh(torch.tensor([5, 3, 2, 4, 0, 1, 4, 3]), 6)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0.],\n",
              "        [1., 0., 0., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0.],\n",
              "        [0., 0., 0., 1., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9OQZqPI-4D5"
      },
      "source": [
        "## Fetch Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlPJDlfF6too"
      },
      "source": [
        "### Script for fetching MIDI from Mutopia Project\n",
        "From Isaiah Hull's Data Camp [article](https://www.datacamp.com/community/tutorials/using-tensorflow-to-compose-music)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXDKsGjb-7Cp"
      },
      "source": [
        "def fetch_data_mutopia():\n",
        "    # Define URL components\n",
        "    url0 = 'https://www.mutopiaproject.org/cgibin/make-table.cgi?startat='\n",
        "    url1 = '&searchingfor=&Composer=&Instrument=&Style=Classical&collection=&id=&solo=&recent=&timelength=&timeunit=&lilyversion=&preview='\n",
        "\n",
        "    scores = []\n",
        "    songNumber = 30\n",
        "    # songNumber = 0 to start at beginning of all matching songs\n",
        "    linkCount = 10\n",
        "\n",
        "    start = time.time()\n",
        "\n",
        "    # Locate and download each MIDI file\n",
        "    m21.environment.set('autoDownload', 'allow')\n",
        "    while linkCount > 0 and len(scores) < 30:  # crashes with > ~30 too much RAM\n",
        "        url = url0 + str(songNumber) + url1\n",
        "        html = urlopen(url)\n",
        "        soup = BeautifulSoup(html.read())\n",
        "        links = soup.find_all('a')\n",
        "        linkCount = 0\n",
        "        for link in links:\n",
        "            href = link['href']\n",
        "            if href.find('.mid') >= 0:\n",
        "                print(href)\n",
        "                linkCount += 1\n",
        "                # download data and keep in `scores` list\n",
        "                scores.append(m21.converter.parse(href))\n",
        "        songNumber += 10\n",
        "        time.sleep(2.0)\n",
        "    print(\"got\", len(scores), \"scores from Mutopia Proj. in\", time.time() - start, \"seconds\")\n",
        "    return scores"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4caN4snDaPa4"
      },
      "source": [
        "# check if data is already ready\n",
        "DATA_SAVE_PATH = \"/content/drive/MyDrive/Computer Science/Deep Learning/\"\n",
        "try:\n",
        "    # to force a reload of data\n",
        "    # raise Exception(\"Forcing reload of data\")\n",
        "\n",
        "    # use pre-downloaded data\n",
        "    tensor_chords = torch.load(DATA_SAVE_PATH+\"tensor_chords.pt\")\n",
        "    tensorX_oh = torch.load(DATA_SAVE_PATH+\"tensorX_oh.pt\")\n",
        "    lengths = torch.load(DATA_SAVE_PATH+\"lengths.pt\")\n",
        "    chord_to_ix = torch.load(DATA_SAVE_PATH+\"chord_to_ix.pt\")\n",
        "    ix_to_chord = {v: k for k, v in chord_to_ix.items()}\n",
        "    DATA_SAVED = True\n",
        "\n",
        "    # configure DataLoader\n",
        "    # offset data/labels so model predicts next data point\n",
        "    tensorX, tensorY = tensor_chords[:, :-1], tensor_chords[:, 1:]\n",
        "\n",
        "    tensordata = torch.utils.data.TensorDataset(tensorX, tensorY)\n",
        "    train_dl = torch.utils.data.DataLoader(tensordata, batch_size=128)\n",
        "\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "    # download from mutopia\n",
        "    DATA_SAVED = False\n",
        "    scores = fetch_data_mutopia()\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMdnoPoRNWi5"
      },
      "source": [
        "# Inspect data\n",
        "# if saved tensor is found, scores are not downloaded\n",
        "if not DATA_SAVED:\n",
        "    print(\"no. of scores:\", len(scores))\n",
        "    show_example(scores[0])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XQ19Rh4EZj7"
      },
      "source": [
        "## Prepare Data for Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dc7B4rIJZE1"
      },
      "source": [
        "def prepare(score, roman=True, figures=True, debug=False):\n",
        "    \"\"\"\n",
        "    Do some programatic analysis of music in the given music21 Stream\n",
        "\n",
        "    Args:\n",
        "        score (music21.stream.Stream): a musical piece to analyze.\n",
        "        roman (Optional, bool): whether to analyze by harmonic function or pitch.\n",
        "            If True, each vertical chord is represented with a Roman numeral.\n",
        "            If False, each vertical chaord is represented as a string of pitch names.\n",
        "        figures (Optional, bool): whether to include figures in Roman numeral representations\n",
        "        debug (Optional, bool): whether to print debug info\n",
        "    \n",
        "    Return:\n",
        "        (Stream, list of string, list of string): Tuple of (new score, chords, durations)\n",
        "    \"\"\"\n",
        "    # transpose to key of C M / c m, like normalization\n",
        "    if debug:\n",
        "        print(\"analyzing key\")\n",
        "    key = score.analyze(\"key\")\n",
        "    if debug:\n",
        "        print(\"transposing\")\n",
        "    offset = m21.interval.Interval(key.tonic, m21.pitch.Pitch(\"C\"))\n",
        "    new_score = score.transpose(offset)\n",
        "\n",
        "    # merge all voices, grouping notes that sound at the same time into chords\n",
        "    if debug:\n",
        "        print(\"grouping chords\")\n",
        "    new_score = new_score.chordify()\n",
        "\n",
        "    # seperate pitch & duration\n",
        "    if debug:\n",
        "        print(\"making chord/duration lists\")\n",
        "    score_chords = [\"start\"]  # prepend a start token to predict starting chords\n",
        "    score_durations = [\"start\"]\n",
        "    repr_chord = repr_roman(figures) if roman else repr_pitches\n",
        "\n",
        "    for element in new_score:\n",
        "        if isinstance(element, m21.chord.Chord):\n",
        "            score_chords.append(repr_chord(element))\n",
        "            score_durations.append(element.duration.quarterLength)\n",
        "        elif isinstance(element, m21.note.Note):  # rare (literally never happens, and it shouldn't)\n",
        "            print(\"found a lone pitch - element.pitch:\", element.pitch)\n",
        "            raise ValueError(\"single pitch\")\n",
        "            # score_chords.append(str(element.pitch))\n",
        "            # score_durations.append(element.duration.quarterLength)\n",
        "\n",
        "    return new_score, score_chords, score_durations\n",
        "\n",
        "def repr_pitches(chord):\n",
        "    return \" \".join(str(pitch) for pitch in chord.pitches)\n",
        "\n",
        "def repr_roman(figures: bool):\n",
        "    k = m21.key.Key(\"C\")\n",
        "    if figures:\n",
        "        def _repr_roman(chord):\n",
        "            return m21.roman.romanNumeralFromChord(chord, k).figure\n",
        "    else:\n",
        "        def _repr_roman(chord):\n",
        "            pass\n",
        "            # return m21.roman.romanNumeralFromChord(chord).\n",
        "    return _repr_roman\n",
        "\n",
        "\n",
        "def dummy_prepare():\n",
        "    \"\"\"\n",
        "    like `prepare()` but on dummy data that should be simpler/easier to learn\n",
        "    \"\"\"\n",
        "    score_chords = [\"start\", \"i\", \"ii\", \"i64\", \"V\", \"i\", \"iv\", \"i64\", \"V\", \"i\"] * 10\n",
        "    score_durations = [1] * len(score_chords)\n",
        "    return None, score_chords, score_durations\n",
        "\n",
        "\n",
        "def get_mappings(elements_by_score):\n",
        "    # filter to unique chords/durations\n",
        "    unique_elements = np.unique([e for score in elements_by_score for e in score])\n",
        "\n",
        "    # create mappings between chord/duration and int\n",
        "    element_to_ix = dict(zip(unique_elements, range(len(unique_elements))))\n",
        "    ix_to_element = {v: k for k, v in element_to_ix.items()}\n",
        "\n",
        "    return element_to_ix, ix_to_element\n",
        "\n",
        "\n",
        "def get_one_hot(elements_by_score, element_to_ix, max_len):\n",
        "    # convert lists of elements into one hot\n",
        "    # pad end with lists of 0s to match length of longest score\n",
        "    one_hot = [None] * len(elements_by_score)\n",
        "    for i, score in enumerate(elements_by_score):\n",
        "        score_elements = [[0] * len(element_to_ix)] * max_len\n",
        "        for j, element in enumerate(score):\n",
        "            encoding = [0] * len(element_to_ix)\n",
        "            encoding[element_to_ix[element]] = 1\n",
        "            score_elements[j] = encoding\n",
        "        one_hot[i] = score_elements\n",
        "    return one_hot\n",
        "\n",
        "\n",
        "def get_indexes(elements_by_score, element_to_ix, max_len):\n",
        "    ixs_by_score = [None] * len(elements_by_score)\n",
        "    for i, score in enumerate(elements_by_score):\n",
        "        score_elements = [0] * max_len\n",
        "        for j, element in enumerate(score):\n",
        "            element_ix = element_to_ix[element]\n",
        "            score_elements[j] = element_ix\n",
        "        ixs_by_score[i] = score_elements\n",
        "    return ixs_by_score"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJmN8GIXEh5Q"
      },
      "source": [
        "if not DATA_SAVED:\n",
        "    new_scores = [None] * len(scores)\n",
        "    chords_by_score = [None] * len(scores)\n",
        "    # durations_by_score = [None] * len(scores)\n",
        "\n",
        "    start = time.time()\n",
        "\n",
        "    # get lists of each sonority and its duration\n",
        "    for i, score in enumerate(scores):\n",
        "        new_score, chords, durs = prepare(score, debug=False)\n",
        "        # _, chords, durs = dummy_prepare()\n",
        "        # new_scores[i] = new_score\n",
        "        chords_by_score[i] = chords\n",
        "        # durations_by_score[i] = durs\n",
        "\n",
        "    print(\"analysis took\", time.time() - start, \"seconds\")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBMqobeUFvSo"
      },
      "source": [
        "#Inspect\n",
        "if not DATA_SAVED:\n",
        "    print(\"no. of scores:\", len(scores))\n",
        "    # show_example(new_scores[0])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ij47q0GNegXV"
      },
      "source": [
        "if not DATA_SAVED:\n",
        "    start = time.time()\n",
        "\n",
        "    # get mappings between sonority/duration and int\n",
        "    chord_to_ix, ix_to_chord = get_mappings(chords_by_score)\n",
        "    # duration_to_int, int_to_duration = get_mappings(durations_by_score)\n",
        "\n",
        "    # sort by sequence length descending\n",
        "    chords_by_score.sort(key=len, reverse=True)\n",
        "    # durations_by_score.sort(key=len, reverse=True)\n",
        "\n",
        "    # need lengths, this solution assumes only 1 mini-batch\n",
        "    lengths = [len(score) - 1 for score in chords_by_score]\n",
        "    max_seq_len = lengths[0] + 1\n",
        "\n",
        "    # use int mappings to get one hot encoding\n",
        "    # or don't because it's slow, takes much RAM\n",
        "    one_hot_chords_by_score = get_one_hot(chords_by_score, chord_to_ix, max_seq_len)\n",
        "    # one_hot_durs_by_score = get_one_hot(durations_by_score, duration_to_int, max_seq_len)\n",
        "\n",
        "    # get chords/durations represented as indices\n",
        "    ix_chords_by_score = get_indexes(chords_by_score, chord_to_ix, max_seq_len)\n",
        "\n",
        "    # create tensors\n",
        "    print(\"making tensors\")\n",
        "    tensor_chords = torch.tensor(ix_chords_by_score)\n",
        "    # tensor_durs = torch.tensor(ix_durs_by_score)\n",
        "    # just use chords for now\n",
        "    packedX = torch.nn.utils.rnn.pack_padded_sequence(tensor_chords, lengths, batch_first=True, enforce_sorted=True)\n",
        "    # divide into train/test sets?\n",
        "\n",
        "    # configure DataLoader\n",
        "    # tensorX = tensorX.permute(1, 0, 2)\n",
        "    # offset data/labels so model predicts next data point\n",
        "    tensorX, tensorY = tensor_chords[:, :-1], tensor_chords[:, 1:]\n",
        "    tensorX_oh = torch.tensor(one_hot_chords_by_score)[:, :-1, :].float()\n",
        "\n",
        "    tensordata = torch.utils.data.TensorDataset(tensorX, tensorY)\n",
        "    train_dl = torch.utils.data.DataLoader(tensordata, batch_size=256)\n",
        "\n",
        "    tensordata_oh = torch.utils.data.TensorDataset(tensorX_oh, tensorY)\n",
        "    train_dl_oh = torch.utils.data.DataLoader(tensordata_oh, batch_size=256)\n",
        "\n",
        "    print(\"formatting took\", time.time() - start, \"seconds\")\n",
        "\n",
        "    torch.save(tensor_chords, DATA_SAVE_PATH+\"tensor_chords.pt\")\n",
        "    torch.save(tensorX_oh, DATA_SAVE_PATH+\"tensorX_oh.pt\")\n",
        "    torch.save(chord_to_ix, DATA_SAVE_PATH+\"chord_to_ix.pt\")\n",
        "    torch.save(lengths, DATA_SAVE_PATH+\"lengths.pt\")\n",
        "    DATA_SAVED = True"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCSmLXsUkKPc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfe1c94c-e6d5-4e12-a4ad-9631514529a9"
      },
      "source": [
        "print(\"X one hot:\", tensorX_oh.shape)\n",
        "print(\"X one hot:\", tensorX_oh.dtype)\n",
        "print(\"X:\", tensorX.shape)\n",
        "print(\"X:\", tensorX.dtype)\n",
        "print(\"X ixs:\", tensorX[0, :10])\n",
        "print(\"Y:\", tensorY.shape)\n",
        "print(\"Y:\", tensorY.dtype)\n",
        "print(\"Y ixs:\", tensorY[0, :10])\n",
        "print(\"lengths:\", lengths)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X one hot: torch.Size([36, 5760, 1668])\n",
            "X one hot: torch.float32\n",
            "X: torch.Size([36, 5760])\n",
            "X: torch.int64\n",
            "X ixs: tensor([1388,  995,  995,  995,  995,  304,  304,  495,  625, 1638])\n",
            "Y: torch.Size([36, 5760])\n",
            "Y: torch.int64\n",
            "Y ixs: tensor([ 995,  995,  995,  995,  304,  304,  495,  625, 1638,  304])\n",
            "lengths: [5760, 4804, 4237, 3995, 3626, 2945, 2824, 2823, 2309, 2276, 2098, 2075, 2040, 1946, 1907, 1653, 1459, 1456, 1443, 1412, 1386, 1248, 1124, 1115, 942, 934, 882, 868, 850, 850, 823, 814, 807, 756, 713, 564]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ipixdE0XBBg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cc44d50-b94e-46b7-9e62-f9d8c916f8c6"
      },
      "source": [
        "print(chord_to_ix)\n",
        "print(\"vocabulary size:\", len(chord_to_ix))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'#i': 0, '#i/o4b3': 1, '#i/ob62': 2, '#i/ob6b54b3': 3, '#i/obb64b3': 4, '#i/obb8b62': 5, '#i2': 6, '#i4': 7, '#i4b3': 8, '#i4bb3': 9, '#i5': 10, '#i54bb3': 11, '#i5b42': 12, '#i5b4bb3': 13, '#i5bb3': 14, '#i5bb42': 15, '#i6': 16, '#i62': 17, '#i63b2': 18, '#i6b5': 19, '#i6bb42': 20, '#i6bb5': 21, '#i6bb52': 22, '#i7bb64': 23, '#ib22': 24, '#ib3': 25, '#ib3b2': 26, '#ib42': 27, '#ib44': 28, '#ib4b32': 29, '#ib5b42': 30, '#ib5bb42': 31, '#ib5bb4b22': 32, '#ib64bb3': 33, '#ib66b42': 34, '#ib66bb5': 35, '#ib7': 36, '#ib74bb3': 37, '#ib75': 38, '#ib75bb4': 39, '#ib76': 40, '#ib76b53': 41, '#ib7b64': 42, '#ib7bb64': 43, '#ib8': 44, '#ib82': 45, '#ib84': 46, '#ib84bb3': 47, '#ib8b64bb3': 48, '#ib8bb3': 49, '#ib8bb64': 50, '#ib8bb7': 51, '#ib8bb7b3': 52, '#ibb3': 53, '#ibb42': 54, '#ibb64': 55, '#ibb64bb3': 56, '#ibb7': 57, '#ibb752': 58, '#ibb75b4': 59, '#ibb75bb4': 60, '#ibb7b3': 61, '#ibb7b4b3': 62, '#ibb7b7': 63, '#ibb7bb3': 64, '#ibb82': 65, '#ibb863': 66, '#io4': 67, '#io4bb3': 68, '#io5b3': 69, '#io5b5b3': 70, '#io6': 71, '#io63b3': 72, '#io6b3': 73, '#io6b33': 74, '#io6b3b2': 75, '#io6bb5b3': 76, '#io6bb5b33': 77, '#io6bb5b3b2': 78, '#io7': 79, '#io7b4': 80, '#io7b64': 81, '#io7bb6b4b2': 82, '#iob5': 83, '#iob54': 84, '#iob55': 85, '#iob5bb3': 86, '#iob62': 87, '#iob64': 88, '#iob64bb3': 89, '#iob66b3': 90, '#iob66b42': 91, '#iob66bb42': 92, '#iob6b42': 93, '#iob6b44bb3': 94, '#iob6bb42': 95, '#iob6bb4b22': 96, '#iob75bb4b2': 97, '#iob76b3': 98, '#iob76bb5b3': 99, '#iob7bb64bb3': 100, '#iob8bb7b5': 101, '#iob8bb7b5b3': 102, '#iobb64': 103, '#iobb64bb3': 104, '#iobb6b44bb3': 105, '#iobb6b64': 106, '#iobb75b2': 107, '#iobb7b5': 108, '#iobb7b54b3': 109, '#iobb7b5bb3': 110, '#iobb7b7b5b3b2': 111, '#iobb7b7b5bb3': 112, '#iobb86b3': 113, '#iobb86bb5b3': 114, '#iv': 115, '#iv/o4b3': 116, '#iv/o6b5b3': 117, '#iv/o6bb5b5b3': 118, '#iv/o7': 119, '#iv/ob62': 120, '#iv/ob64b3': 121, '#iv/ob6b42': 122, '#iv/ob7b5': 123, '#iv2': 124, '#iv4': 125, '#iv4b3': 126, '#iv4bb3': 127, '#iv5': 128, '#iv54': 129, '#iv5bb4bb3': 130, '#iv6': 131, '#iv63bb2': 132, '#iv64': 133, '#iv6b5': 134, '#iv6bb5': 135, '#iv6bb53': 136, '#iv6bb5b2': 137, '#iv7b2': 138, '#iv7bb6b2': 139, '#ivb22': 140, '#ivb3': 141, '#ivb3b2': 142, '#ivb42': 143, '#ivb432': 144, '#ivb44': 145, '#ivb4b32': 146, '#ivb54': 147, '#ivb5b42': 148, '#ivb64b3': 149, '#ivb66': 150, '#ivb7': 151, '#ivb75bb4': 152, '#ivb76b5': 153, '#ivb76bb5': 154, '#ivb7b3': 155, '#ivb7bb3': 156, '#ivb8': 157, '#ivb84': 158, '#ivb85': 159, '#ivb85bb3': 160, '#ivb8b3': 161, '#ivb8bb3': 162, '#ivbb3': 163, '#ivbb42': 164, '#ivbb7': 165, '#ivbb75': 166, '#ivbb752': 167, '#ivbb7b3': 168, '#ivbb7b4b3': 169, '#ivbb7b64': 170, '#ivbb8b42': 171, '#ivbb8b75bb4': 172, '#ivo4': 173, '#ivo4bb3': 174, '#ivo5b3': 175, '#ivo5b5b3': 176, '#ivo6': 177, '#ivo63b3': 178, '#ivo6b3b2': 179, '#ivo6bb5b3': 180, '#ivo7': 181, '#ivo76b3': 182, '#ivo76bb5b3': 183, '#ivo7b4': 184, '#ivo7b4b2': 185, '#ivo7b4bb2': 186, '#ivo7bb6b4b2': 187, '#ivob5': 188, '#ivob54': 189, '#ivob5b2': 190, '#ivob5b3b2': 191, '#ivob5b4b3': 192, '#ivob5bb3': 193, '#ivob62': 194, '#ivob64': 195, '#ivob64bb3': 196, '#ivob654': 197, '#ivob6b42': 198, '#ivob6b4b32': 199, '#ivob6b54bb3': 200, '#ivob75b2': 201, '#ivob75bb4b2': 202, '#ivob76b3': 203, '#ivob76b55b2': 204, '#ivob76bb5b3': 205, '#ivob7b64bb3': 206, '#ivob87b4': 207, '#ivob8bb7b6b5b4b32': 208, '#ivobb64': 209, '#ivobb64bb3': 210, '#ivobb7b5': 211, '#ivobb7b5b4b3': 212, '#ivobb7b5bb3': 213, '#v': 214, '#v/o43': 215, '#v/o7': 216, '#v/o7b5': 217, '#v/o7b5b4b3': 218, '#v2': 219, '#v5bb42': 220, '#v6': 221, '#v65': 222, '#v6b5': 223, '#v6b52': 224, '#v6b55': 225, '#v6b5b2': 226, '#v7': 227, '#vb22': 228, '#vb3': 229, '#vb42': 230, '#vb55bb42': 231, '#vb5b42': 232, '#vb5bb42': 233, '#vb66': 234, '#vb66b5': 235, '#vb66b52': 236, '#vb7': 237, '#vb74bb3': 238, '#vb75b4': 239, '#vb76': 240, '#vb76b5': 241, '#vb77': 242, '#vb7b3': 243, '#vb7b4b3': 244, '#vb7b4bb3': 245, '#vb7bb3': 246, '#vb8': 247, '#vb8b7': 248, '#vb8b7b3': 249, '#vb8bb3': 250, '#vb8bb42': 251, '#vbb3': 252, '#vbb3b2': 253, '#vbb3b3': 254, '#vbb42': 255, '#vbb75b4': 256, '#vo4': 257, '#vo4b3': 258, '#vo5b3': 259, '#vo6': 260, '#vo63b3': 261, '#vo6b3': 262, '#vo6b32': 263, '#vo6b3b2': 264, '#vo6b5b3': 265, '#vo6b5b3b2': 266, '#vob44b3': 267, '#vob5': 268, '#vob54': 269, '#vob5b2': 270, '#vob5b4b3': 271, '#vob5b4bb3b3': 272, '#vob5bb3': 273, '#vob62': 274, '#vob64': 275, '#vob64b3': 276, '#vob66b3': 277, '#vob66b5b3': 278, '#vob6b42': 279, '#vob6b44b3': 280, '#vob6bb42': 281, '#vob75b2': 282, '#vob75b4b2': 283, '#vob76b3': 284, '#vob76b5b3': 285, '#vob7b5': 286, '#vob7b5bb3': 287, '#vob7b64b3': 288, '#vob7bb64b3': 289, '#vob8b5': 290, '#vob8b5b3': 291, '#vob8b7b5': 292, '#vob8b7b5b3': 293, '#vob8b7b5bb3': 294, '#vobb64': 295, '#vobb64b3': 296, '#vobb6b44': 297, '#vobb6b64b3': 298, '#vobb75b2': 299, '#vobb75b4b2': 300, '#vobb86b3': 301, 'Fr43': 302, 'Ger65': 303, 'I': 304, 'I#764': 305, 'I#7654#4': 306, 'I#83': 307, 'I#853': 308, 'I#8532': 309, 'I#8b73': 310, 'I#8b75#53': 311, 'I#8b75#543': 312, 'I#8b753': 313, 'I#8b773': 314, 'I+': 315, 'I+#532': 316, 'I+#543': 317, 'I+#8#53': 318, 'I+5#543': 319, 'I+6': 320, 'I+6#32': 321, 'I+64': 322, 'I+64b3': 323, 'I+6b5#3': 324, 'I+75#2': 325, 'I+764': 326, 'I+764#4': 327, 'I+7643': 328, 'I+b7#53': 329, 'I32': 330, 'I42': 331, 'I43': 332, 'I432': 333, 'I5#43': 334, 'I532': 335, 'I543': 336, 'I5432': 337, 'I5b33': 338, 'I6': 339, 'I6#6': 340, 'I6#63': 341, 'I6#6b5': 342, 'I6#6b53': 343, 'I63#2': 344, 'I63#3': 345, 'I632': 346, 'I64': 347, 'I64#4b3': 348, 'I642#2': 349, 'I6432': 350, 'I64b3': 351, 'I65': 352, 'I652': 353, 'I654': 354, 'I6543': 355, 'I6b5': 356, 'I7': 357, 'I72': 358, 'I732': 359, 'I742': 360, 'I743': 361, 'I7432': 362, 'I752': 363, 'I7532': 364, 'I7542': 365, 'I7543': 366, 'I75432': 367, 'I75b4': 368, 'I75b42': 369, 'I76': 370, 'I76#63': 371, 'I762': 372, 'I763': 373, 'I764': 374, 'I7643': 375, 'I764b3': 376, 'I765': 377, 'I7652': 378, 'I7653': 379, 'I76532': 380, 'I7654': 381, 'I76542': 382, 'I76543': 383, 'I765432': 384, 'I76b53': 385, 'II': 386, 'II#3': 387, 'II#32': 388, 'II#3b2': 389, 'II#3b22': 390, 'II#42': 391, 'II#4b32': 392, 'II#643': 393, 'II#654': 394, 'II#6b54': 395, 'II#75#3': 396, 'II#752': 397, 'II#754': 398, 'II#7542': 399, 'II#7652': 400, 'II#76542': 401, 'II#86#42': 402, 'II5#32': 403, 'II5#3b2': 404, 'II5#42': 405, 'II54#3': 406, 'II54#32': 407, 'II6': 408, 'II6#42': 409, 'II6#4b32': 410, 'II6#53': 411, 'II63#2': 412, 'II64': 413, 'II65': 414, 'II65#2': 415, 'II65#5': 416, 'II65#53': 417, 'II652': 418, 'II7#2': 419, 'II7#3': 420, 'II7#32': 421, 'II7#3b2': 422, 'II7#64': 423, 'II7#643': 424, 'II7#7#3': 425, 'II7#752': 426, 'II74#2': 427, 'II74#3': 428, 'II75#3': 429, 'II75#32': 430, 'II75#3b2': 431, 'II754#3': 432, 'II76#2': 433, 'II764#2': 434, 'II7653': 435, 'III': 436, 'III#3': 437, 'III#42': 438, 'III#432': 439, 'III#643': 440, 'III#754': 441, 'III/o#6543': 442, 'III/o65b3': 443, 'III3#3': 444, 'III5#3#2': 445, 'III5#32': 446, 'III54#3': 447, 'III54#3#2': 448, 'III6': 449, 'III6#42': 450, 'III6#432': 451, 'III64': 452, 'III65': 453, 'III7#2': 454, 'III7#3': 455, 'III7#32': 456, 'III74#2': 457, 'III75#3': 458, 'IIIb663': 459, 'IIIb8#3': 460, 'IIIb85#3': 461, 'IIIo76b3': 462, 'IIIo7b4#2': 463, 'IIIob5#3': 464, 'IIb66#42': 465, 'IIb763': 466, 'IIb765': 467, 'IIb7653': 468, 'IV': 469, 'IV#83': 470, 'IV#832': 471, 'IV+': 472, 'IV+#532': 473, 'IV+6': 474, 'IV+64': 475, 'IV+7#42': 476, 'IV+75#2': 477, 'IV+b76#54': 478, 'IV3#2': 479, 'IV32': 480, 'IV32#2': 481, 'IV42': 482, 'IV43': 483, 'IV432': 484, 'IV53#2': 485, 'IV532': 486, 'IV543': 487, 'IV5432': 488, 'IV5b33': 489, 'IV5b43': 490, 'IV5b432': 491, 'IV6': 492, 'IV6#54': 493, 'IV632': 494, 'IV64': 495, 'IV64b3': 496, 'IV64b33': 497, 'IV65': 498, 'IV652': 499, 'IV654': 500, 'IV6543': 501, 'IV6b5': 502, 'IV6b53b2': 503, 'IV6b55': 504, 'IV6b553': 505, 'IV6b5b2': 506, 'IV7': 507, 'IV7#65#52': 508, 'IV7#72': 509, 'IV72': 510, 'IV732': 511, 'IV742': 512, 'IV743': 513, 'IV7432': 514, 'IV75#53': 515, 'IV752': 516, 'IV754': 517, 'IV75b4': 518, 'IV75b42': 519, 'IV76': 520, 'IV763': 521, 'IV764': 522, 'IV7653': 523, 'IV7654': 524, 'IV76543': 525, 'IV7b22': 526, 'IVb33': 527, 'IVb664': 528, 'IVb73': 529, 'IVb732': 530, 'IVb753': 531, 'IVb75b43': 532, 'IVb764': 533, 'IVb7b33': 534, 'IVb86': 535, 'IVb863': 536, 'IVb87#65#52': 537, 'Ib33': 538, 'Ib664': 539, 'Ib73': 540, 'Ib732': 541, 'Ib743': 542, 'Ib75#43': 543, 'Ib75#53': 544, 'Ib753': 545, 'Ib7532': 546, 'Ib7543': 547, 'Ib75b33': 548, 'Ib86': 549, 'Ib863': 550, 'It6': 551, 'V': 552, 'V#73': 553, 'V#732': 554, 'V#753': 555, 'V#7532': 556, 'V#7543': 557, 'V#75432': 558, 'V#764': 559, 'V#7643': 560, 'V#8#7543': 561, 'V#83': 562, 'V#842': 563, 'V#853': 564, 'V#8542': 565, 'V#8642': 566, 'V#87#43': 567, 'V#873': 568, 'V#8753': 569, 'V#87543': 570, 'V#875b33': 571, 'V#87b33': 572, 'V32': 573, 'V3b2': 574, 'V42': 575, 'V42#2': 576, 'V43': 577, 'V432': 578, 'V5#43': 579, 'V532': 580, 'V53b2': 581, 'V542': 582, 'V543': 583, 'V5432': 584, 'V54b332': 585, 'V5b33': 586, 'V6': 587, 'V6#5': 588, 'V6#53': 589, 'V6#542': 590, 'V6#63': 591, 'V63#2': 592, 'V632': 593, 'V64': 594, 'V64#3': 595, 'V64#43': 596, 'V642#2': 597, 'V643#3': 598, 'V6432': 599, 'V65': 600, 'V65#2': 601, 'V65#5': 602, 'V65#53': 603, 'V652': 604, 'V653#2': 605, 'V6532': 606, 'V654': 607, 'V6542': 608, 'V6543': 609, 'V7': 610, 'V7#43': 611, 'V7#73': 612, 'V7#753': 613, 'V72': 614, 'V732': 615, 'V73b2': 616, 'V74#32': 617, 'V742': 618, 'V743': 619, 'V75#43': 620, 'V75#542': 621, 'V752': 622, 'V7532': 623, 'V754': 624, 'V7542': 625, 'V7543': 626, 'V75432': 627, 'V76': 628, 'V762': 629, 'V763': 630, 'V7632': 631, 'V764': 632, 'V7642': 633, 'V7643': 634, 'V765': 635, 'V7653': 636, 'V7654': 637, 'V76542': 638, 'VI': 639, 'VI#3': 640, 'VI#32': 641, 'VI#42': 642, 'VI#643': 643, 'VI#6b443': 644, 'VI#6b543': 645, 'VI#75#3': 646, 'VI#752': 647, 'VI/o#643': 648, 'VI/o65b3': 649, 'VI5#3b2': 650, 'VI54#3': 651, 'VI6': 652, 'VI6#42': 653, 'VI6#643': 654, 'VI64': 655, 'VI65': 656, 'VI65#5': 657, 'VI7#2': 658, 'VI7#3': 659, 'VI7#32': 660, 'VI7#3b2': 661, 'VI75#3': 662, 'VI75#32': 663, 'VI76#64': 664, 'VI763': 665, 'VI764#2': 666, 'VIb6653': 667, 'VIb76': 668, 'VIb763': 669, 'VIb7653': 670, 'VIb8#3': 671, 'VIo#64': 672, 'VIo#654': 673, 'VIo#6b54': 674, 'VIo6b3': 675, 'VIob5#3': 676, 'VIob5#3b2': 677, 'Vb33': 678, 'Vb664': 679, 'Vb76': 680, 'Vb76#5': 681, 'Vb86': 682, 'Vb863': 683, 'bIII': 684, 'bIII##76': 685, 'bIII##76#5': 686, 'bIII##86': 687, 'bIII##863': 688, 'bIII#3': 689, 'bIII#3##2': 690, 'bIII#3##3': 691, 'bIII#3##3##2': 692, 'bIII#3#2': 693, 'bIII#42': 694, 'bIII#6##6#54': 695, 'bIII#6##6#54#3': 696, 'bIII#6##64': 697, 'bIII#6##64#3': 698, 'bIII#6#54': 699, 'bIII#64#3': 700, 'bIII#7#3': 701, 'bIII#7#3#2': 702, 'bIII#7#64': 703, 'bIII#75#3': 704, 'bIII#752': 705, 'bIII#76': 706, 'bIII#76#5': 707, 'bIII#763': 708, 'bIII#8#3': 709, 'bIII#8#7#6##65#5#4#3##3#2##2': 710, 'bIII+#5#3#2': 711, 'bIII+#6#4#32': 712, 'bIII+#6#42': 713, 'bIII+#6#54': 714, 'bIII+#6#54#3': 715, 'bIII+#64': 716, 'bIII+#64#3': 717, 'bIII+#664': 718, 'bIII+#7##65#2': 719, 'bIII+#7#5#3': 720, 'bIII+#7#5#3#2': 721, 'bIII+#75#2': 722, 'bIII+#76#3': 723, 'bIII+#76#5#3': 724, 'bIII+5#3': 725, 'bIII+5#33': 726, 'bIII+6': 727, 'bIII+6#5#3': 728, 'bIII+6#6#3': 729, 'bIII+7#6#4#2': 730, 'bIII5#3##2': 731, 'bIII5#3##3': 732, 'bIII5#3#2': 733, 'bIII5#4#3': 734, 'bIII54#3': 735, 'bIII6': 736, 'bIII6#42': 737, 'bIII6#5': 738, 'bIII6#53': 739, 'bIII6#63': 740, 'bIII63#2': 741, 'bIII64': 742, 'bIII7#2': 743, 'bIII74#2': 744, 'bVI': 745, 'bVI##86': 746, 'bVI#3': 747, 'bVI#3##3': 748, 'bVI#3#2': 749, 'bVI#32': 750, 'bVI#4#32': 751, 'bVI#42': 752, 'bVI#7#3': 753, 'bVI#75#3': 754, 'bVI#76': 755, 'bVI#8#3': 756, 'bVI+#7#6#54': 757, 'bVI+#7#64': 758, 'bVI+#7#65#2': 759, 'bVI+5#3': 760, 'bVI+6': 761, 'bVI+76#5#3': 762, 'bVI5#3##3': 763, 'bVI5#3##32': 764, 'bVI5#3#2': 765, 'bVI6': 766, 'bVI6#42': 767, 'bVI6#5': 768, 'bVI6#5#4#32': 769, 'bVI6#53': 770, 'bVI64': 771, 'bVI7#2': 772, 'bVI7#64#2##2': 773, 'bVI76': 774, 'bVI763': 775, 'bVII': 776, 'bVII##76': 777, 'bVII##76#5#3': 778, 'bVII##87#7#6#4##4#2': 779, 'bVII#3': 780, 'bVII#3##2': 781, 'bVII#3#2': 782, 'bVII#4#3##32#2': 783, 'bVII#42': 784, 'bVII#5#3##2': 785, 'bVII#5#3#2': 786, 'bVII#5#3#2##2': 787, 'bVII#5#4#3': 788, 'bVII#5#4#3##2': 789, 'bVII#54#3': 790, 'bVII#54#3#2': 791, 'bVII#6#54': 792, 'bVII#643': 793, 'bVII#7#3': 794, 'bVII#7#5##5#3#2': 795, 'bVII#7#5#3': 796, 'bVII#7#54#3': 797, 'bVII#76': 798, 'bVII#76#5': 799, 'bVII+##5#3#2': 800, 'bVII+##54#3': 801, 'bVII+##54#3#2': 802, 'bVII+#64': 803, 'bVII+#664': 804, 'bVII+#7##5#3': 805, 'bVII+#7#5##5#3#2': 806, 'bVII+5#3': 807, 'bVII+5#33': 808, 'bVII+6': 809, 'bVII+6#5##3': 810, 'bVII+7##4#2': 811, 'bVII+7#6##4#2': 812, 'bVII5#42': 813, 'bVII6': 814, 'bVII6#5': 815, 'bVII64': 816, 'bVII65': 817, 'bVII65#3': 818, 'bVII7#2': 819, 'bVII7#3': 820, 'bVII7#5#3': 821, 'bVII7#6#2': 822, 'biii': 823, 'biii##3': 824, 'biii##3##2': 825, 'biii##3#2': 826, 'biii##4#32': 827, 'biii##54': 828, 'biii##6##54': 829, 'biii##6##54#3': 830, 'biii##6#54': 831, 'biii##6#54#3': 832, 'biii##64': 833, 'biii##76': 834, 'biii##76#5': 835, 'biii##763': 836, 'biii##87##2': 837, 'biii##874': 838, 'biii#4##4#32': 839, 'biii#5##54': 840, 'biii#54': 841, 'biii#6##6#54#3': 842, 'biii#7': 843, 'biii#7##3': 844, 'biii#7##3#2': 845, 'biii#7##76': 846, 'biii#75': 847, 'biii#75##3': 848, 'biii#75##3#2': 849, 'biii#75#3##3': 850, 'biii#76': 851, 'biii#76#5': 852, 'biii#76#6': 853, 'biii#763': 854, 'biii#8': 855, 'biii#8#76': 856, 'biii#84': 857, 'biii#85': 858, 'biii#86': 859, 'biii#874': 860, 'biii+##54': 861, 'biii+##54#4': 862, 'biii+##6#54': 863, 'biii+##64': 864, 'biii+#5': 865, 'biii+#5##2': 866, 'biii+#5##3': 867, 'biii+#5##3#2': 868, 'biii+#5#2': 869, 'biii+#54': 870, 'biii+#6##4#32': 871, 'biii+#6##64': 872, 'biii+#62': 873, 'biii+#7#5': 874, 'biii+#7#5##3': 875, 'biii+#7#5##3#2': 876, 'biii+#76#3': 877, 'biii+#76#5#3': 878, 'biii+4': 879, 'biii+4#3': 880, 'biii+4#4': 881, 'biii+5#5##3': 882, 'biii+6#3': 883, 'biii+7#4': 884, 'biii+7#4##2': 885, 'biii2': 886, 'biii4': 887, 'biii4#3': 888, 'biii4#4': 889, 'biii5': 890, 'biii5##2': 891, 'biii5##3': 892, 'biii5##3#2': 893, 'biii5#2': 894, 'biii5#2##2': 895, 'biii5#3##3#2': 896, 'biii6': 897, 'biii6##4#32': 898, 'biii6##42': 899, 'biii6#5': 900, 'biii62': 901, 'biii7##2': 902, 'biii7#6##2': 903, 'biii7#64##2': 904, 'biii74': 905, 'biii74##2': 906, 'bvi': 907, 'bvi##3': 908, 'bvi##3#2': 909, 'bvi##32': 910, 'bvi##42': 911, 'bvi##432': 912, 'bvi#3##3': 913, 'bvi#54': 914, 'bvi#7': 915, 'bvi#7##3': 916, 'bvi#7##32': 917, 'bvi#75##32': 918, 'bvi#76': 919, 'bvi#8': 920, 'bvi+##6#54': 921, 'bvi+##64': 922, 'bvi+#5': 923, 'bvi+#5##3': 924, 'bvi+#5#2': 925, 'bvi+#52#2': 926, 'bvi+#54': 927, 'bvi+#54#4': 928, 'bvi+4': 929, 'bvi+4#3': 930, 'bvi+4#4': 931, 'bvi+5#5#2': 932, 'bvi+54': 933, 'bvi+6#3': 934, 'bvi+76#3': 935, 'bvi2': 936, 'bvi4': 937, 'bvi4#3': 938, 'bvi5': 939, 'bvi5##3': 940, 'bvi5##32': 941, 'bvi5#2': 942, 'bvi5#5': 943, 'bvi52': 944, 'bvi54': 945, 'bvi6': 946, 'bvi6##42': 947, 'bvi62': 948, 'bvi7##2': 949, 'bvi7#76': 950, 'bvi74': 951, 'bvi76': 952, 'bvii': 953, 'bvii##54': 954, 'bvii##8##54': 955, 'bvii##84': 956, 'bvii##87#4': 957, 'bvii#5': 958, 'bvii#5##2': 959, 'bvii#5##5': 960, 'bvii#5##54': 961, 'bvii#5#2': 962, 'bvii#5#2##2': 963, 'bvii#54': 964, 'bvii#62': 965, 'bvii#7': 966, 'bvii#7#5': 967, 'bvii#8': 968, 'bvii#87#4': 969, 'bvii+##5': 970, 'bvii+##5##2': 971, 'bvii+##54': 972, 'bvii+##54#4': 973, 'bvii+##62': 974, 'bvii+#5##5': 975, 'bvii+#5##5##2': 976, 'bvii+#5##54': 977, 'bvii+#8##5': 978, 'bvii+#84': 979, 'bvii+#843': 980, 'bvii+4': 981, 'bvii+4#3': 982, 'bvii+4#4': 983, 'bvii+4#4#3': 984, 'bvii+7##4': 985, 'bvii2': 986, 'bvii2#2': 987, 'bvii4': 988, 'bvii4#3': 989, 'bvii43': 990, 'bvii7': 991, 'bvii7#4': 992, 'bvii7#5': 993, 'bvii7#7': 994, 'i': 995, 'i#5b42': 996, 'i#7b64': 997, 'i#7b64b3': 998, 'i#7b664': 999, 'i#8': 1000, 'i#8#7b64': 1001, 'i#84': 1002, 'i#85': 1003, 'i#854': 1004, 'i#87b6543': 1005, 'i#8b3': 1006, 'i#8b64': 1007, 'i#8b654': 1008, 'i#8b7': 1009, 'i#8b75': 1010, 'i+#5': 1011, 'i+#5#4b3': 1012, 'i+#52': 1013, 'i+#54#4b3': 1014, 'i+#54b3': 1015, 'i+#54b32': 1016, 'i+#5b3': 1017, 'i+#5b32': 1018, 'i+#62': 1019, 'i+#6b42': 1020, 'i+#7b64': 1021, 'i+#7b654': 1022, 'i+#8#5#4b3': 1023, 'i+#8#5b3': 1024, 'i+4': 1025, 'i+4#4': 1026, 'i+43': 1027, 'i+4b3': 1028, 'i+5#5': 1029, 'i+5#5#4b3': 1030, 'i+5#52': 1031, 'i+5#54b3': 1032, 'i+54': 1033, 'i+54#4': 1034, 'i+6#3': 1035, 'i+6#32': 1036, 'i+6#6#3': 1037, 'i+6#6b53#3': 1038, 'i+63#3': 1039, 'i+63#32': 1040, 'i+65#3': 1041, 'i+6b5#3': 1042, 'i+6b5#32': 1043, 'i+6b55#3': 1044, 'i+7#4': 1045, 'i+7#43b2': 1046, 'i+7#4b2': 1047, 'i+7#5': 1048, 'i+7#54b3': 1049, 'i+75#5b32': 1050, 'i+76#3': 1051, 'i+76b5#3': 1052, 'i+76b53#32': 1053, 'i+7b64': 1054, 'i+7b654': 1055, 'i+b64': 1056, 'i+b64#4': 1057, 'i+b64b3': 1058, 'i+b654': 1059, 'i+b7#5': 1060, 'i+b7#5#4b3': 1061, 'i+b75#2': 1062, 'i2': 1063, 'i2#2': 1064, 'i4': 1065, 'i4#4b3': 1066, 'i43': 1067, 'i4b3': 1068, 'i4b33': 1069, 'i5': 1070, 'i5#4b3': 1071, 'i5#5': 1072, 'i5#5b3': 1073, 'i5#5b42': 1074, 'i52': 1075, 'i54': 1076, 'i54b3': 1077, 'i5b32': 1078, 'i5b33': 1079, 'i5b42': 1080, 'i6': 1081, 'i6#65b432': 1082, 'i6#6b42': 1083, 'i6#6b53': 1084, 'i62': 1085, 'i62#2': 1086, 'i63#2': 1087, 'i63#3': 1088, 'i632': 1089, 'i64': 1090, 'i65': 1091, 'i6b42': 1092, 'i6b5': 1093, 'i7': 1094, 'i74': 1095, 'i74b2': 1096, 'i74b3': 1097, 'i754b3': 1098, 'i754b32': 1099, 'i75b3': 1100, 'i75b32': 1101, 'i76': 1102, 'i763': 1103, 'i76b53': 1104, 'i76b532': 1105, 'i7b2': 1106, 'i7b3': 1107, 'i7b33': 1108, 'i7b64': 1109, 'i7b643': 1110, 'i7b654': 1111, 'i7b6543': 1112, 'ib3': 1113, 'ib32': 1114, 'ib42': 1115, 'ib432': 1116, 'ib64#4': 1117, 'ib643': 1118, 'ib64b3': 1119, 'ib654': 1120, 'ib6543': 1121, 'ib664': 1122, 'ib7': 1123, 'ib75': 1124, 'ib75#5': 1125, 'ib752': 1126, 'ib754': 1127, 'ib75b3': 1128, 'ib75b4': 1129, 'ib7652#2': 1130, 'ib7b3': 1131, 'ii': 1132, 'ii#542': 1133, 'ii#7': 1134, 'ii#73': 1135, 'ii#732': 1136, 'ii#86': 1137, 'ii#862': 1138, 'ii#865': 1139, 'ii#8653': 1140, 'ii/o43': 1141, 'ii/o65b3': 1142, 'ii/o65b33': 1143, 'ii/o754b2': 1144, 'ii/o7b53': 1145, 'ii/ob62': 1146, 'ii/ob642': 1147, 'ii/ob6542': 1148, 'ii2': 1149, 'ii3#3': 1150, 'ii32': 1151, 'ii3b2': 1152, 'ii4': 1153, 'ii42': 1154, 'ii43': 1155, 'ii432': 1156, 'ii4b32': 1157, 'ii5': 1158, 'ii5#43': 1159, 'ii52': 1160, 'ii532': 1161, 'ii54': 1162, 'ii54#42': 1163, 'ii542': 1164, 'ii543': 1165, 'ii6': 1166, 'ii6#52': 1167, 'ii6#53': 1168, 'ii6#532': 1169, 'ii62': 1170, 'ii632': 1171, 'ii64': 1172, 'ii64#3': 1173, 'ii6432': 1174, 'ii64b32': 1175, 'ii65': 1176, 'ii65#2': 1177, 'ii65#5': 1178, 'ii652': 1179, 'ii6532': 1180, 'ii6542': 1181, 'ii6543': 1182, 'ii6b54': 1183, 'ii7': 1184, 'ii7#43': 1185, 'ii7#7': 1186, 'ii7#75': 1187, 'ii7#754': 1188, 'ii72': 1189, 'ii732': 1190, 'ii74': 1191, 'ii742': 1192, 'ii743': 1193, 'ii743#3': 1194, 'ii75#4': 1195, 'ii752': 1196, 'ii7532': 1197, 'ii754': 1198, 'ii754#4': 1199, 'ii76': 1200, 'ii76#53': 1201, 'ii763': 1202, 'ii7632': 1203, 'ii764': 1204, 'ii7642': 1205, 'ii7643': 1206, 'ii7653': 1207, 'ii76b54': 1208, 'ii7b652': 1209, 'iib553': 1210, 'iib76': 1211, 'iib765': 1212, 'iib7653': 1213, 'iii': 1214, 'iii#54': 1215, 'iii#76': 1216, 'iii#763': 1217, 'iii#7653': 1218, 'iii#876': 1219, 'iii/o43': 1220, 'iii/o7b5': 1221, 'iii/o7b53': 1222, 'iii/ob642': 1223, 'iii2': 1224, 'iii3#2': 1225, 'iii3#3': 1226, 'iii32': 1227, 'iii4': 1228, 'iii42': 1229, 'iii43': 1230, 'iii432': 1231, 'iii5': 1232, 'iii5#2': 1233, 'iii532': 1234, 'iii54': 1235, 'iii542': 1236, 'iii543': 1237, 'iii6': 1238, 'iii6#54': 1239, 'iii62': 1240, 'iii64': 1241, 'iii6432': 1242, 'iii65': 1243, 'iii652': 1244, 'iii6532': 1245, 'iii654': 1246, 'iii6543': 1247, 'iii6b33': 1248, 'iii7': 1249, 'iii7#7653': 1250, 'iii72': 1251, 'iii732': 1252, 'iii74': 1253, 'iii742': 1254, 'iii752': 1255, 'iii753#2': 1256, 'iii7532': 1257, 'iii754': 1258, 'iii76': 1259, 'iii762': 1260, 'iii763': 1261, 'iii764': 1262, 'iii7642': 1263, 'iii765': 1264, 'iii7653': 1265, 'iiib553': 1266, 'iiib8': 1267, 'iiib83': 1268, 'iiib84': 1269, 'iiib85': 1270, 'iiib85#2': 1271, 'iiib864': 1272, 'iiio': 1273, 'iiio#54': 1274, 'iiio4': 1275, 'iiio5b53': 1276, 'iiio6': 1277, 'iiio6#654': 1278, 'iiio63b3': 1279, 'iiio64': 1280, 'iiio6b32': 1281, 'iiio6b33': 1282, 'iiio7b4': 1283, 'iiio7b42': 1284, 'iiiob5': 1285, 'iiiob5#2': 1286, 'iiiob53#3': 1287, 'iiiob532': 1288, 'iiiob8b5': 1289, 'iio': 1290, 'iio4': 1291, 'iio54': 1292, 'iio6': 1293, 'iio63b3': 1294, 'iio64': 1295, 'iio75b2': 1296, 'iio764': 1297, 'iio7b4': 1298, 'iio7b42': 1299, 'iiob5': 1300, 'iiob52': 1301, 'iiob54': 1302, 'iv': 1303, 'iv#54': 1304, 'iv#8': 1305, 'iv#84': 1306, 'iv#85': 1307, 'iv#874': 1308, 'iv#8b64': 1309, 'iv+#5': 1310, 'iv+#5#2': 1311, 'iv+#52': 1312, 'iv+#52#2': 1313, 'iv+#54': 1314, 'iv+#54b3': 1315, 'iv+#5b3': 1316, 'iv+#62': 1317, 'iv+#8#5': 1318, 'iv+4': 1319, 'iv+43': 1320, 'iv+4b3': 1321, 'iv+5#5#2': 1322, 'iv+5#54': 1323, 'iv+5#5b3': 1324, 'iv+54': 1325, 'iv+6#3': 1326, 'iv+6#6#3': 1327, 'iv+63#3': 1328, 'iv+65#3': 1329, 'iv+7#4': 1330, 'iv+74#4': 1331, 'iv+76#3': 1332, 'iv+7b64': 1333, 'iv+b64': 1334, 'iv+b75#2': 1335, 'iv+b75b4#2': 1336, 'iv2': 1337, 'iv4': 1338, 'iv4#4': 1339, 'iv43': 1340, 'iv4b3': 1341, 'iv5': 1342, 'iv5#2': 1343, 'iv5#5': 1344, 'iv5#5#2': 1345, 'iv5#54': 1346, 'iv52': 1347, 'iv52#2': 1348, 'iv54': 1349, 'iv54#4': 1350, 'iv54b3': 1351, 'iv54b32': 1352, 'iv5b32': 1353, 'iv5b4b3': 1354, 'iv5b4b32': 1355, 'iv6': 1356, 'iv6#62': 1357, 'iv62': 1358, 'iv64': 1359, 'iv65': 1360, 'iv6b42': 1361, 'iv6b5': 1362, 'iv7': 1363, 'iv74': 1364, 'iv74#4': 1365, 'iv75b3': 1366, 'iv75b4b32': 1367, 'iv76': 1368, 'iv763': 1369, 'iv763b2': 1370, 'iv7653b2': 1371, 'iv7b2': 1372, 'iv7b3': 1373, 'iv7b64': 1374, 'ivb3': 1375, 'ivb32': 1376, 'ivb42': 1377, 'ivb643': 1378, 'ivb654': 1379, 'ivb7': 1380, 'ivb75': 1381, 'ivb752': 1382, 'ivb752#2': 1383, 'ivb75b3': 1384, 'ivb775': 1385, 'ivb7752#2': 1386, 'ivb7b3': 1387, 'start': 1388, 'v': 1389, 'v#5b42': 1390, 'v#7': 1391, 'v#75': 1392, 'v#754b32': 1393, 'v#75b3': 1394, 'v#75b32': 1395, 'v#75b33': 1396, 'v#7b3': 1397, 'v#7b33': 1398, 'v#7b64': 1399, 'v#8': 1400, 'v#82': 1401, 'v#85': 1402, 'v#854b33': 1403, 'v#85b3': 1404, 'v#862': 1405, 'v#865#5b4432#2': 1406, 'v#87': 1407, 'v#875': 1408, 'v#875b3': 1409, 'v#8b3': 1410, 'v2': 1411, 'v2#2': 1412, 'v4': 1413, 'v4#3': 1414, 'v4#4': 1415, 'v43': 1416, 'v43#3': 1417, 'v5': 1418, 'v52': 1419, 'v54': 1420, 'v54b3': 1421, 'v54b32': 1422, 'v5b2': 1423, 'v5b32': 1424, 'v5b33': 1425, 'v5b332': 1426, 'v5b42': 1427, 'v6': 1428, 'v6#53': 1429, 'v6#6': 1430, 'v6#63': 1431, 'v6#65': 1432, 'v6#653': 1433, 'v62': 1434, 'v63#2': 1435, 'v632': 1436, 'v64': 1437, 'v65': 1438, 'v65#2': 1439, 'v652': 1440, 'v65b42#2': 1441, 'v65b442#2': 1442, 'v6b42': 1443, 'v6b42#2': 1444, 'v7': 1445, 'v7#7': 1446, 'v7#75': 1447, 'v7#7b6654#4b332': 1448, 'v74': 1449, 'v74b2': 1450, 'v74b3': 1451, 'v75b3': 1452, 'v75b33': 1453, 'v76': 1454, 'v76#532': 1455, 'v763': 1456, 'v765': 1457, 'v7b2': 1458, 'v7b3': 1459, 'v7b64': 1460, 'v7b654#3': 1461, 'vb3': 1462, 'vb32': 1463, 'vb33': 1464, 'vb3b2': 1465, 'vb42': 1466, 'vb432': 1467, 'vb64#3': 1468, 'vb64#43': 1469, 'vb643': 1470, 'vb75#4': 1471, 'vb752': 1472, 'vb754': 1473, 'vb76': 1474, 'vi': 1475, 'vi#7': 1476, 'vi#73': 1477, 'vi#732': 1478, 'vi#82': 1479, 'vi/o43': 1480, 'vi/o65b3': 1481, 'vi/o76b42': 1482, 'vi/o7b5': 1483, 'vi/o7b53': 1484, 'vi/ob62': 1485, 'vi/ob642': 1486, 'vi2': 1487, 'vi3#3': 1488, 'vi32': 1489, 'vi3b2': 1490, 'vi4': 1491, 'vi4#3': 1492, 'vi42': 1493, 'vi43': 1494, 'vi432': 1495, 'vi5': 1496, 'vi52': 1497, 'vi532': 1498, 'vi54': 1499, 'vi542': 1500, 'vi543': 1501, 'vi5432': 1502, 'vi5b2': 1503, 'vi6': 1504, 'vi62': 1505, 'vi632': 1506, 'vi64': 1507, 'vi64#3': 1508, 'vi6432': 1509, 'vi65': 1510, 'vi654': 1511, 'vi6543': 1512, 'vi6b44': 1513, 'vi6b543': 1514, 'vi7': 1515, 'vi72': 1516, 'vi732': 1517, 'vi74': 1518, 'vi742': 1519, 'vi743': 1520, 'vi752': 1521, 'vi754': 1522, 'vi754#4': 1523, 'vi75432': 1524, 'vi76': 1525, 'vi76#5': 1526, 'vi762': 1527, 'vi763': 1528, 'vi7643': 1529, 'vi765': 1530, 'vi7653': 1531, 'vib553': 1532, 'vib76': 1533, 'vib763': 1534, 'vib765': 1535, 'vib7653': 1536, 'vib8': 1537, 'vib83': 1538, 'vib84': 1539, 'vib864': 1540, 'vii': 1541, 'vii#5': 1542, 'vii#532': 1543, 'vii#54': 1544, 'vii#543': 1545, 'vii#62': 1546, 'vii#6432': 1547, 'vii#76#3': 1548, 'vii/o42': 1549, 'vii/o43': 1550, 'vii/o62': 1551, 'vii/o6432': 1552, 'vii/o65': 1553, 'vii/o6532': 1554, 'vii/o6543': 1555, 'vii/o7': 1556, 'vii/o7543': 1557, 'vii/o7642': 1558, 'vii/o7653': 1559, 'vii/ob6653': 1560, 'vii2': 1561, 'vii32': 1562, 'vii4': 1563, 'vii42': 1564, 'vii43': 1565, 'vii4b3': 1566, 'vii5#5': 1567, 'vii542': 1568, 'vii6': 1569, 'vii6#32': 1570, 'vii6#54': 1571, 'vii64': 1572, 'vii64b3': 1573, 'vii65': 1574, 'vii65#3': 1575, 'vii654': 1576, 'vii6543': 1577, 'vii65b2': 1578, 'vii6b5': 1579, 'vii6b52': 1580, 'vii7': 1581, 'vii7#42': 1582, 'vii7#5': 1583, 'vii7#532': 1584, 'vii7#765': 1585, 'vii72': 1586, 'vii75b4': 1587, 'vii75b4#2': 1588, 'vii75b44': 1589, 'vii76': 1590, 'vii76#3': 1591, 'vii76#42': 1592, 'vii764': 1593, 'vii765': 1594, 'vii765#3': 1595, 'vii7b62': 1596, 'viib22': 1597, 'viib7': 1598, 'viib7#5': 1599, 'viib73': 1600, 'viib732': 1601, 'viib743': 1602, 'viib8': 1603, 'viib8#5': 1604, 'viib8#5#2': 1605, 'viib83': 1606, 'viib8b7': 1607, 'viio': 1608, 'viio#54': 1609, 'viio#763': 1610, 'viio#7632': 1611, 'viio#84': 1612, 'viio#84b3': 1613, 'viio4': 1614, 'viio42': 1615, 'viio4b3': 1616, 'viio5': 1617, 'viio5#2': 1618, 'viio5#5': 1619, 'viio52': 1620, 'viio53#2': 1621, 'viio532': 1622, 'viio54': 1623, 'viio543': 1624, 'viio543#2': 1625, 'viio5432': 1626, 'viio5b432': 1627, 'viio6': 1628, 'viio6#54': 1629, 'viio62': 1630, 'viio632': 1631, 'viio64': 1632, 'viio64b3': 1633, 'viio654': 1634, 'viio6b5': 1635, 'viio74': 1636, 'viio74#42': 1637, 'viio742': 1638, 'viio7432': 1639, 'viio752': 1640, 'viio763': 1641, 'viio764': 1642, 'viio7654': 1643, 'viio7b642': 1644, 'viiob663': 1645, 'viiob75': 1646, 'viiob753': 1647, 'viiob774': 1648, 'viiob7753': 1649, 'vio': 1650, 'vio4': 1651, 'vio54': 1652, 'vio5b53': 1653, 'vio6': 1654, 'vio6#5b3': 1655, 'vio63b3': 1656, 'vio64': 1657, 'vio654': 1658, 'vio6b32': 1659, 'vio75b2': 1660, 'vio7b4': 1661, 'vio7b42': 1662, 'viob5': 1663, 'viob52': 1664, 'viob54': 1665, 'viob554': 1666, 'viob76b3': 1667}\n",
            "vocabulary size: 1668\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hHYB89sJIrN"
      },
      "source": [
        "## Define Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5-UM082kWM0"
      },
      "source": [
        "class LSTM(torch.nn.Module):\n",
        "    def __init__(self, input_size, lstm_hidden_size, lstm_layers, bi=True, output_size=None):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.lstm_hidden_size = lstm_hidden_size\n",
        "        self.lstm_layers = lstm_layers\n",
        "        self.bi = bi\n",
        "\n",
        "        self.lstm = torch.nn.LSTM(input_size, lstm_hidden_size, lstm_layers, bidirectional=bi)\n",
        "        self.fc_out = torch.nn.Linear(lstm_hidden_size * (1+bi), output_size or input_size)\n",
        "\n",
        "    def forward(self, x, lens, hc_old=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x has shape (batch_size, seq_len, input_size)\n",
        "            hc_old (tensor, tensor): optional, old hidden/cell state tuple from last time step\n",
        "        \"\"\"\n",
        "        if hc_old is None:\n",
        "            hc_old = self.__init_hidden_and_cell_state(x.shape[0])\n",
        "\n",
        "        # \"pack\" variable-len sequences to avoid using autograd on padding values\n",
        "        x_pack = pack_padded_sequence(x, lens, batch_first=True, enforce_sorted=True)\n",
        "        lstm_out_pack, hc = self.lstm(x_pack, hc_old)\n",
        "        lstm_out, _lens = pad_packed_sequence(lstm_out_pack, batch_first=True)\n",
        "\n",
        "        out = F.softmax(self.fc_out(lstm_out), dim=2)\n",
        "        \n",
        "        return out, hc\n",
        "    \n",
        "    def __init_hidden_and_cell_state(self, batch_size):\n",
        "        # Uses __ 'name mangling' becaue who knows what names PyTorch already uses\n",
        "\n",
        "        # create a 0-initialized hidden/cell state tuple for RNN to start a new sequence\n",
        "        hc = (\n",
        "            # shape is, like, (no. directions*no. layers, batch_size, hidden_size)\n",
        "            torch.zeros(((1+self.bi)*self.lstm_layers, batch_size, self.lstm_hidden_size)).to(device),\n",
        "            torch.zeros(((1+self.bi)*self.lstm_layers, batch_size, self.lstm_hidden_size)).to(device)\n",
        "        )\n",
        "        return hc\n",
        "    \n",
        "    @property\n",
        "    def has_embedding(self):\n",
        "        return False\n",
        "\n",
        "\n",
        "class Embedding_LSTM(torch.nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, lstm_hidden_size, lstm_layers, bi=True):\n",
        "        super(Embedding_LSTM, self).__init__()\n",
        "\n",
        "        # use an embedding to better understand chord realationships\n",
        "        self.embed = torch.nn.Embedding(vocab_size, embed_size)\n",
        "\n",
        "        # use LSTM I already set up\n",
        "        self.lstm_model = LSTM(embed_size, lstm_hidden_size, lstm_layers, bi=bi, output_size=vocab_size)\n",
        "    \n",
        "    def forward(self, x, lens, hc_old=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x has shape (batch_size, seq_len, 1)\n",
        "            hc_old (tensor, tensor): optional, old hidden/cell state from last time step\n",
        "        \"\"\"\n",
        "        embed_out = self.embed(x)\n",
        "        out, hc = self.lstm_model(embed_out, lens, hc_old)\n",
        "        \n",
        "        return out, hc\n",
        "    \n",
        "    @property\n",
        "    def has_embedding(self):\n",
        "        return True\n",
        "\n",
        "class GRU(torch.nn.Module):\n",
        "    def __init__(self, input_size, lstm_hidden_size, lstm_layers, bi=True, output_size=None):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.lstm_hidden_size = lstm_hidden_size\n",
        "        self.lstm_layers = lstm_layers\n",
        "        self.bi = bi\n",
        "\n",
        "        self.lstm = torch.nn.LSTM(input_size, lstm_hidden_size, lstm_layers, bidirectional=bi)\n",
        "        self.fc_out = torch.nn.Linear(lstm_hidden_size * (1+bi), output_size or input_size)\n",
        "\n",
        "    def forward(self, x, lens, hc_old=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x has shape (batch_size, seq_len, input_size)\n",
        "            hc_old (tensor, tensor): optional, old hidden/cell state tuple from last time step\n",
        "        \"\"\"\n",
        "        if hc_old is None:\n",
        "            hc_old = self.__init_hidden_and_cell_state(x.shape[0])\n",
        "\n",
        "        # \"pack\" variable-len sequences to avoid using autograd on padding values\n",
        "        x_pack = pack_padded_sequence(x, lens, batch_first=True, enforce_sorted=True)\n",
        "        lstm_out_pack, hc = self.lstm(x_pack, hc_old)\n",
        "        lstm_out, _lens = pad_packed_sequence(lstm_out_pack, batch_first=True)\n",
        "\n",
        "        out = F.softmax(self.fc_out(lstm_out), dim=2)\n",
        "        \n",
        "        return out, hc\n",
        "    \n",
        "    def __init_hidden_and_cell_state(self, batch_size):\n",
        "        # Uses __ 'name mangling' becaue who knows what names PyTorch already uses\n",
        "\n",
        "        # create a 0-initialized hidden/cell state tuple for RNN to start a new sequence\n",
        "        hc = (\n",
        "            # shape is, like, (no. directions*no. layers, batch_size, hidden_size)\n",
        "            torch.zeros(((1+self.bi)*self.lstm_layers, batch_size, self.lstm_hidden_size)).to(device),\n",
        "            torch.zeros(((1+self.bi)*self.lstm_layers, batch_size, self.lstm_hidden_size)).to(device)\n",
        "        )\n",
        "        return hc\n",
        "    \n",
        "    @property\n",
        "    def has_embedding(self):\n",
        "        return False"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqLzP4nvY9y_"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdpCLGv6ZN9C"
      },
      "source": [
        "class StatReporter:\n",
        "    def start(self):\n",
        "        self.start_time = time.time()\n",
        "        self.elapsed = 0\n",
        "        self.target = 0\n",
        "        self.loss = None\n",
        "\n",
        "    def iteration(self, epoch, i, loss):\n",
        "        self.loss = loss\n",
        "\n",
        "        iteration_time = time.time() - self.start_time\n",
        "        self.elapsed += iteration_time\n",
        "        self.start_time = time.time()\n",
        "        if self.elapsed > self.target:\n",
        "            print(f\"Epoch {epoch+1:2d}, iteration {i+1:3d}:  Loss = {loss:.3f}  Iteration time = {iteration_time:0.3f}\")\n",
        "            self.target += 10\n",
        "\n",
        "    def end(self):\n",
        "        print(f\"Training complete.  Elapsed time: {self.elapsed:.2f} seconds  Final loss: {self.loss:0.3f}\")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysW-wzJpY_4I"
      },
      "source": [
        "def train_model(model, dataloader, lengths, epochs, lr=0.001, debug=False, track_loss=True):\n",
        "    \"\"\"\n",
        "    Train a given model on given data for a given number of epochs\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): model to train\n",
        "        dataloader (torch.utils.data.DataLoader): training data\n",
        "        epochs (int): number of epochs to train for\n",
        "        debug (Optional, bool): whether to print shape/dtype info\n",
        "    \"\"\"\n",
        "    # make sure model is on the gpu (or appropriate device)\n",
        "    model.to(device)\n",
        "\n",
        "    # set up loss function and optimization algorithm\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    # criterion = torch.nn.NLLLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999))\n",
        "\n",
        "    # set up stat recording\n",
        "    stats = StatReporter()\n",
        "    stats.start()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for i, data in enumerate(dataloader):\n",
        "            # send data to gpu\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "            if debug:\n",
        "                print(\"inputs shape:\", inputs.shape)\n",
        "                print(\"inputs dtype:\", inputs.dtype)\n",
        "\n",
        "            # zero out the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # apply forward propagation\n",
        "            outputs, _hc = model(inputs, lengths)\n",
        "            if debug:\n",
        "                print(\"outputs shape:\", outputs.shape)\n",
        "                print(\"outputs dtype:\", outputs.dtype)\n",
        "\n",
        "            # calculate loss\n",
        "            # rearrange tensor to expected shape for loss func\n",
        "            outputs = outputs.permute(0, 2, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "            # backprop\n",
        "            loss.backward()\n",
        "            # update model parameters\n",
        "            optimizer.step()\n",
        "\n",
        "            # show a cost/loss over iteration graph\n",
        "            if track_loss:\n",
        "                losses.append(float(loss))\n",
        "            # if time.time()-start_time > 10 or epoch==0 or epoch==epochs-1:\n",
        "            #     # Plot the cost function over the iterations completed so far\n",
        "            #     clear_output(wait=True)\n",
        "            #     plt.figure(figsize=(12, 8))\n",
        "            #     plt.ylabel(\"Loss\")\n",
        "            #     plt.xlabel(\"Iteration\")\n",
        "            #     plt.plot(range(1, len(losses)+1), losses)\n",
        "            #     plt.show()\n",
        "            #     start_time = time.time()  # store a new time for triggering the next update\n",
        "\n",
        "            # record stats for this iteration\n",
        "            stats.iteration(epoch, i, loss)\n",
        "            \n",
        "\n",
        "    # end stat recording\n",
        "    stats.end"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlXCUD0cj838"
      },
      "source": [
        "# instantiate model based on no. of possible chords in language\n",
        "# model = Embedding_LSTM(len(chord_to_int), 4, 8, 1).to(device)\n",
        "model = Embedding_LSTM(len(chord_to_ix), 128, 256, 1, bi=True).to(device)\n",
        "losses = []"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klEgEpgyng17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3424f11f-8d0f-40ce-ae19-34cfefafdb59"
      },
      "source": [
        "# train for some no. of epochs\n",
        "# train_model(model, train_dl_oh, lengths, 1000, lr=0.001)\n",
        "train_model(model, train_dl, lengths, 1000, lr=0.1)\n",
        "# backup_model = deepcopy(model)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  1, iteration   1:  Loss = 7.419  Iteration time = 1.181\n",
            "Epoch 10, iteration   1:  Loss = 7.390  Iteration time = 1.013\n",
            "Epoch 20, iteration   1:  Loss = 7.376  Iteration time = 1.014\n",
            "Epoch 30, iteration   1:  Loss = 7.286  Iteration time = 1.018\n",
            "Epoch 40, iteration   1:  Loss = 6.906  Iteration time = 1.017\n",
            "Epoch 49, iteration   1:  Loss = 6.730  Iteration time = 1.025\n",
            "Epoch 59, iteration   1:  Loss = 6.707  Iteration time = 1.021\n",
            "Epoch 69, iteration   1:  Loss = 6.704  Iteration time = 1.035\n",
            "Epoch 79, iteration   1:  Loss = 6.703  Iteration time = 1.043\n",
            "Epoch 88, iteration   1:  Loss = 6.702  Iteration time = 1.027\n",
            "Epoch 98, iteration   1:  Loss = 6.702  Iteration time = 1.039\n",
            "Epoch 107, iteration   1:  Loss = 6.702  Iteration time = 1.047\n",
            "Epoch 117, iteration   1:  Loss = 6.701  Iteration time = 1.053\n",
            "Epoch 126, iteration   1:  Loss = 6.701  Iteration time = 1.057\n",
            "Epoch 136, iteration   1:  Loss = 6.701  Iteration time = 1.061\n",
            "Epoch 145, iteration   1:  Loss = 6.701  Iteration time = 1.058\n",
            "Epoch 155, iteration   1:  Loss = 6.701  Iteration time = 1.048\n",
            "Epoch 165, iteration   1:  Loss = 6.701  Iteration time = 1.052\n",
            "Epoch 174, iteration   1:  Loss = 6.701  Iteration time = 1.050\n",
            "Epoch 184, iteration   1:  Loss = 6.701  Iteration time = 1.044\n",
            "Epoch 193, iteration   1:  Loss = 6.701  Iteration time = 1.041\n",
            "Epoch 203, iteration   1:  Loss = 6.701  Iteration time = 1.051\n",
            "Epoch 212, iteration   1:  Loss = 6.701  Iteration time = 1.055\n",
            "Epoch 222, iteration   1:  Loss = 6.701  Iteration time = 1.044\n",
            "Epoch 231, iteration   1:  Loss = 6.701  Iteration time = 1.051\n",
            "Epoch 241, iteration   1:  Loss = 6.701  Iteration time = 1.051\n",
            "Epoch 250, iteration   1:  Loss = 6.700  Iteration time = 1.038\n",
            "Epoch 260, iteration   1:  Loss = 6.700  Iteration time = 1.043\n",
            "Epoch 269, iteration   1:  Loss = 6.700  Iteration time = 1.053\n",
            "Epoch 279, iteration   1:  Loss = 6.700  Iteration time = 1.048\n",
            "Epoch 288, iteration   1:  Loss = 6.700  Iteration time = 1.047\n",
            "Epoch 298, iteration   1:  Loss = 6.700  Iteration time = 1.045\n",
            "Epoch 307, iteration   1:  Loss = 6.700  Iteration time = 1.043\n",
            "Epoch 317, iteration   1:  Loss = 6.700  Iteration time = 1.047\n",
            "Epoch 327, iteration   1:  Loss = 6.700  Iteration time = 1.050\n",
            "Epoch 336, iteration   1:  Loss = 6.700  Iteration time = 1.043\n",
            "Epoch 346, iteration   1:  Loss = 6.700  Iteration time = 1.052\n",
            "Epoch 355, iteration   1:  Loss = 6.700  Iteration time = 1.046\n",
            "Epoch 365, iteration   1:  Loss = 6.700  Iteration time = 1.054\n",
            "Epoch 374, iteration   1:  Loss = 6.700  Iteration time = 1.049\n",
            "Epoch 384, iteration   1:  Loss = 6.700  Iteration time = 1.054\n",
            "Epoch 393, iteration   1:  Loss = 6.700  Iteration time = 1.045\n",
            "Epoch 403, iteration   1:  Loss = 6.700  Iteration time = 1.043\n",
            "Epoch 412, iteration   1:  Loss = 6.700  Iteration time = 1.049\n",
            "Epoch 422, iteration   1:  Loss = 6.700  Iteration time = 1.053\n",
            "Epoch 431, iteration   1:  Loss = 6.700  Iteration time = 1.051\n",
            "Epoch 441, iteration   1:  Loss = 6.700  Iteration time = 1.052\n",
            "Epoch 450, iteration   1:  Loss = 6.700  Iteration time = 1.052\n",
            "Epoch 460, iteration   1:  Loss = 6.700  Iteration time = 1.045\n",
            "Epoch 469, iteration   1:  Loss = 6.700  Iteration time = 1.057\n",
            "Epoch 479, iteration   1:  Loss = 6.700  Iteration time = 1.050\n",
            "Epoch 488, iteration   1:  Loss = 6.700  Iteration time = 1.063\n",
            "Epoch 498, iteration   1:  Loss = 6.700  Iteration time = 1.048\n",
            "Epoch 507, iteration   1:  Loss = 6.700  Iteration time = 1.062\n",
            "Epoch 517, iteration   1:  Loss = 6.700  Iteration time = 1.053\n",
            "Epoch 527, iteration   1:  Loss = 6.700  Iteration time = 1.052\n",
            "Epoch 536, iteration   1:  Loss = 6.700  Iteration time = 1.041\n",
            "Epoch 546, iteration   1:  Loss = 6.700  Iteration time = 1.056\n",
            "Epoch 555, iteration   1:  Loss = 6.700  Iteration time = 1.041\n",
            "Epoch 565, iteration   1:  Loss = 6.700  Iteration time = 1.054\n",
            "Epoch 574, iteration   1:  Loss = 6.700  Iteration time = 1.055\n",
            "Epoch 584, iteration   1:  Loss = 6.700  Iteration time = 1.054\n",
            "Epoch 593, iteration   1:  Loss = 6.700  Iteration time = 1.046\n",
            "Epoch 603, iteration   1:  Loss = 6.700  Iteration time = 1.067\n",
            "Epoch 612, iteration   1:  Loss = 6.700  Iteration time = 1.047\n",
            "Epoch 622, iteration   1:  Loss = 6.700  Iteration time = 1.039\n",
            "Epoch 631, iteration   1:  Loss = 6.700  Iteration time = 1.046\n",
            "Epoch 641, iteration   1:  Loss = 6.700  Iteration time = 1.057\n",
            "Epoch 650, iteration   1:  Loss = 6.700  Iteration time = 1.051\n",
            "Epoch 660, iteration   1:  Loss = 6.700  Iteration time = 1.062\n",
            "Epoch 670, iteration   1:  Loss = 6.700  Iteration time = 1.047\n",
            "Epoch 679, iteration   1:  Loss = 6.700  Iteration time = 1.045\n",
            "Epoch 689, iteration   1:  Loss = 6.700  Iteration time = 1.033\n",
            "Epoch 698, iteration   1:  Loss = 6.700  Iteration time = 1.037\n",
            "Epoch 708, iteration   1:  Loss = 6.700  Iteration time = 1.046\n",
            "Epoch 717, iteration   1:  Loss = 6.700  Iteration time = 1.055\n",
            "Epoch 727, iteration   1:  Loss = 6.700  Iteration time = 1.053\n",
            "Epoch 736, iteration   1:  Loss = 6.700  Iteration time = 1.058\n",
            "Epoch 746, iteration   1:  Loss = 6.700  Iteration time = 1.047\n",
            "Epoch 755, iteration   1:  Loss = 6.700  Iteration time = 1.051\n",
            "Epoch 765, iteration   1:  Loss = 6.700  Iteration time = 1.046\n",
            "Epoch 774, iteration   1:  Loss = 6.700  Iteration time = 1.054\n",
            "Epoch 784, iteration   1:  Loss = 6.700  Iteration time = 1.055\n",
            "Epoch 793, iteration   1:  Loss = 6.700  Iteration time = 1.058\n",
            "Epoch 803, iteration   1:  Loss = 6.700  Iteration time = 1.066\n",
            "Epoch 812, iteration   1:  Loss = 6.700  Iteration time = 1.054\n",
            "Epoch 822, iteration   1:  Loss = 6.700  Iteration time = 1.050\n",
            "Epoch 831, iteration   1:  Loss = 6.700  Iteration time = 1.053\n",
            "Epoch 841, iteration   1:  Loss = 6.700  Iteration time = 1.052\n",
            "Epoch 850, iteration   1:  Loss = 6.700  Iteration time = 1.049\n",
            "Epoch 860, iteration   1:  Loss = 6.700  Iteration time = 1.054\n",
            "Epoch 869, iteration   1:  Loss = 6.700  Iteration time = 1.045\n",
            "Epoch 879, iteration   1:  Loss = 6.700  Iteration time = 1.047\n",
            "Epoch 888, iteration   1:  Loss = 6.700  Iteration time = 1.051\n",
            "Epoch 898, iteration   1:  Loss = 6.700  Iteration time = 1.042\n",
            "Epoch 907, iteration   1:  Loss = 6.700  Iteration time = 1.042\n",
            "Epoch 917, iteration   1:  Loss = 6.700  Iteration time = 1.061\n",
            "Epoch 926, iteration   1:  Loss = 6.700  Iteration time = 1.053\n",
            "Epoch 936, iteration   1:  Loss = 6.700  Iteration time = 1.051\n",
            "Epoch 946, iteration   1:  Loss = 6.700  Iteration time = 1.054\n",
            "Epoch 955, iteration   1:  Loss = 6.700  Iteration time = 1.052\n",
            "Epoch 965, iteration   1:  Loss = 6.700  Iteration time = 1.048\n",
            "Epoch 974, iteration   1:  Loss = 6.700  Iteration time = 1.063\n",
            "Epoch 984, iteration   1:  Loss = 6.700  Iteration time = 1.056\n",
            "Epoch 993, iteration   1:  Loss = 6.700  Iteration time = 1.046\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idj-v36f4kE0"
      },
      "source": [
        "# Continuous training\n",
        "\n",
        "# epochs = 0\n",
        "# while True:\n",
        "#     train_model(model, train_dl, lengths, 100, lr=0.3, track_loss=False)\n",
        "#     torch.save(model, DATA_SAVE_PATH+\"long_trained_model_4-7-2021_2.pt\")\n",
        "#     epochs += 100\n",
        "#     print(epochs)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd3Hjz7P1n1z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "c5c2bca1-4d66-4139-a7f3-7f7265443c29"
      },
      "source": [
        "clear_output(wait=True)\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.plot(range(1, len(losses)+1), losses)\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 720,
              "height": 479
            },
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UOp1NEDn9UI"
      },
      "source": [
        "## Test Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ULADM-qtEpx"
      },
      "source": [
        "# model_no_embed = model\n",
        "# model_embed = model\n",
        "# model_embed_bi = model\n",
        "# model = torch.load(DATA_SAVE_PATH+\"long_trained_model_4-7-2021.pt\")"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPYqyDJ2oG7L"
      },
      "source": [
        "def vector_to_chord(vect):\n",
        "    \"\"\"\n",
        "    Convert a single class vector to the chord it represents\n",
        "    \"\"\"\n",
        "    ix = torch.argmax(vect)\n",
        "    c_str = ix_to_chord[ix.item()]\n",
        "\n",
        "    try:\n",
        "        if \" \" in c_str:  # multiple pitches\n",
        "            c = m21.chord.Chord(c_str)\n",
        "        else:  # one pitch\n",
        "            c = m21.note.Note(c_str)\n",
        "\n",
        "        return c\n",
        "    except:\n",
        "        # a roman numeral\n",
        "        return m21.roman.RomanNumeral(c_str, m21.key.Key(\"C\"))\n",
        "\n",
        "\n",
        "def model_out_to_scores(output, ix_to_chord, debug=False):\n",
        "    \"\"\"\n",
        "    Convert the model's output into music format\n",
        "\n",
        "    Args:\n",
        "        output (Tensor): shape (batches, seq_len, XfeaturesX 1).  ouptut from model.\n",
        "    \n",
        "    Returns list of music21.Stream: more comprehensible musical representation of output.\n",
        "    \"\"\"\n",
        "    scores = []\n",
        "\n",
        "    # for each score in the batch\n",
        "    for score in output:\n",
        "        if debug:\n",
        "            print(\"predictions:\\n\", score)\n",
        "        # music21.Stream will represent the score\n",
        "        stream = m21.stream.Stream()\n",
        "        chord_ixs = torch.argmax(score, dim=1)\n",
        "        # for each chord in the score\n",
        "        for ix in chord_ixs:\n",
        "            if debug:\n",
        "                print(\"chord ix:\", ix.item())\n",
        "                print(\"chord str:\", \"'\"+ix_to_chord[ix.item()]+\"'\")\n",
        "            # convert from index to chord, add to stream\n",
        "            chord_str = ix_to_chord[ix.item()]\n",
        "            \n",
        "            try:\n",
        "                if \" \" in chord_str:  # multiple pitches\n",
        "                    chord = m21.chord.Chord(chord_str)\n",
        "                    stream.append(chord)\n",
        "                else:  # Chord needs multiple, just create a Note\n",
        "                    note = m21.note.Note(chord_str)\n",
        "                    stream.append(note)\n",
        "            except:\n",
        "                # a roman numeral\n",
        "                stream.append(m21.roman.RomanNumeral(chord_str, m21.key.Key(\"C\")))\n",
        "        # add stream to list of scores\n",
        "        scores.append(stream)\n",
        "\n",
        "    return scores\n",
        "\n",
        "\n",
        "def test_on_training_excerpt(model, device, t_y):\n",
        "    \"\"\"\n",
        "    Provide a model with input taken from training data, print some info on its output\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): The model to test\n",
        "        device: Processor to keep data on\n",
        "        t_y (int): The number of tokens to generate\n",
        "    \"\"\"\n",
        "    # get appropriate input to give model\n",
        "    if model.has_embedding:\n",
        "        # inputs should be indices referring to columns in embedding matrix\n",
        "        input = tensorX[0][None, :t_y, ...].to(device)\n",
        "    else:\n",
        "        # inputs should be one-hot vectors referring to vocab entries\n",
        "        input = tensorX_oh[0][None, :t_y, ...].to(device)\n",
        "    \n",
        "    print(\"input shape:\", input.shape)\n",
        "    \n",
        "    # apply model to the input data\n",
        "    out, _h = model(input, [t_y])\n",
        "\n",
        "    # process the model's output\n",
        "    scores_out = model_out_to_scores(out, ix_to_chord, debug=False)\n",
        "    sample_score = scores_out[0]  # first (and only) piece given to model\n",
        "    show_example(sample_score)\n",
        "\n",
        "\n",
        "def test_generation(model, device, t_y):\n",
        "    \"\"\"\n",
        "    Sample from a model's outputs to generate a sequence that it thinks is likely\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): The model to test\n",
        "        device: Processor to keep data on\n",
        "        t_y (int): The number of tokens to generate\n",
        "    \"\"\"\n",
        "    # get an appropriate starting input for the model\n",
        "    start_ix = [chord_to_ix[\"start\"]]\n",
        "    if model.has_embedding:\n",
        "        # if the model uses an embedding layer\n",
        "        input = torch.tensor(start_ix)[None, ...].to(device)\n",
        "    else:\n",
        "        # if the model needs one-hot vector inputs\n",
        "        input = ixs_to_oh(start_ix, len(chord_to_ix))[None, ...].to(device)\n",
        "    \n",
        "    # repeatedly give the model its last predictions and hidden/cell state to get next prediction\n",
        "    hc = None  # start with 0 hidden/cell state\n",
        "    s = m21.stream.Stream()\n",
        "    for t in range(t_y):\n",
        "        out, hc = model(input, [1], hc)\n",
        "        s.append(vector_to_chord(out))\n",
        "        print(\"next prediction:\", out)\n",
        "\n",
        "        input = torch.argmax(out, dim=1)\n",
        "        # just for no-embedding model that needs one-hot input:\n",
        "        if not model.has_embedding:\n",
        "            input = ixs_to_oh(input, len(ix_to_chord)).to(device)\n",
        "\n",
        "    show_example(s)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybdQ8GAY0kyr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "c105bd04-1bca-424a-d4dd-e58fe205eaba"
      },
      "source": [
        "# random input of one hot vectors\n",
        "input = np.eye(len(chord_to_ix))[np.random.choice(len(chord_to_ix), 10)]\n",
        "input = torch.tensor(np.expand_dims(input, axis=0)).float()\n",
        "\n",
        "# input = torch.randint(0, len(chord_to_ix), (1, 10))\n",
        "# print(\"input:\", input)\n",
        "\n",
        "out, _h = model(input.to(device), [10])\n",
        "\n",
        "scores_out = model_out_to_scores(out, ix_to_chord, debug=True)\n",
        "\n",
        "sample_score = scores_out[0].flat\n",
        "show_example(sample_score)\n",
        "# print(\"roman numerals:\")\n",
        "# for c in sample_score.chordify():\n",
        "#     print(m21.roman.romanNumeralFromChord(c, m21.key.Key(\"C\")))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-28f2072db74d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# print(\"input:\", input)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mscores_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_out_to_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mix_to_chord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-4f4d6c04391b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, lens, hc_old)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mhc_old\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mcell\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlast\u001b[0m \u001b[0mtime\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \"\"\"\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0membed_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhc_old\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    156\u001b[0m         return F.embedding(\n\u001b[1;32m    157\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1914\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1916\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.cuda.FloatTensor instead (while checking arguments for embedding)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGMaymm8Bxee"
      },
      "source": [
        "# Try the model on some of its training data\n",
        "test_on_training_excerpt(model, device, 15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0u-6pCR_9Ox"
      },
      "source": [
        "# Sample from the model \n",
        "test_generation(model, device, 15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeVkB0dvRkDN"
      },
      "source": [
        "# # try to free up RAM\n",
        "# try:\n",
        "#     del scores\n",
        "#     del new_scores\n",
        "# except Exception as e:\n",
        "#     print(e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEFALKYaFnNx"
      },
      "source": [
        "# torch.save(model, DATA_SAVE_PATH+\"model.pt\")\n",
        "# torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7bcbTj0uk_u"
      },
      "source": [
        "# model.embed.weight.shape\n",
        "# torch.argmax(torch.cat((counts[1:6010], counts[6013:])))\n",
        "# counts[0]\n",
        "# Counter(all_chords)\n",
        "# print(chord_to_int)\n",
        "# model.embed.weight\n",
        "all_chords = [c for s in chords_by_score for c in s]\n",
        "Counter(all_chords).most_common(20)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}